[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cyclonetix: Comprehensive Design & Roadmap Document",
    "section": "",
    "text": "Cyclonetix is a lightweight, Rust-based workflow orchestrator designed to be fast, easy to use, and highly scalable. It is built for both cloud-native and on-premises deployments, supporting outcome-based scheduling, self-assembling DAGs, and manual DAG execution.\nUnlike traditional orchestrators, Cyclonetix aims to be: - Effortlessly simple to get started with - Exceptionally fast and lightweight - Flexible enough for both beginners and enterprise-scale workloads - Clever by design, reducing user cognitive load - Capable of advanced scheduling mechanisms (outcome-based scheduling + explicit DAG execution)\n\n\n\n\n\n\nCyclonetix consists of the following key components:\n\n\n\n\n\n\n\nComponent\nDescription\n\n\n\n\nOrchestrator\nBuilds execution graphs, evaluates task readiness, and schedules work.\n\n\nWorker\nPicks up tasks from queues and executes them.\n\n\nExecution Graph\nSelf-assembled DAG built from tasks, outcomes, and dependencies.\n\n\nState Manager (Redis, PostgreSQL, In-Memory Dev Mode)\nStores task states, execution metadata, and scheduled outcomes. Supports different backends for different environments.\n\n\nUI (Axum SSR + Tabler + Cytoscape.js)\nProvides real-time execution tracking and DAG visualization.\n\n\nAuthentication (OAuth, Basic Auth, API Keys)\nEnsures secure access to Cyclonetix resources.\n\n\n\n\n\n\n\nUsers schedule an “Outcome” (final goal/task)\nOrchestrator determines required tasks to complete the Outcome (self-assembling DAG)\nTasks are assigned to queues, picked up by workers, executed, and tracked in Redis or another backend\nCompleted tasks trigger evaluations for the next executable tasks via events\nExecution continues until the full DAG is completed\n\n\n\n\nCyclonetix supports two scheduling models: - Outcome-Based Scheduling (Self-assembling DAGs) - Users schedule an Outcome (e.g., deploy-model), and Cyclonetix dynamically determines the required execution steps. - Manual DAG Execution - Users define DAGs explicitly in YAML and execute them as structured workflows.\n\n\n\n\nContexts allow global state to be passed through execution graphs, ensuring variables and configurations are inherited properly.\nParameter Sets allow specific configurations to be associated with tasks, ensuring fine-grained control over execution and reuse of tasks with different “flavourings”. Parameters can be included in dependency declarations.\nContexts can be hierarchical, enabling seamless overrides for scoped execution. Base contexts loaded from repo and partially overridden by user-defined contexts values at scheduling time.\n**Support for common macros like ${DATE}, ${TIME}, ${RANDOM} for parameter and context values.\n\n\n\n\n\nEvaluation tasks allow dynamic decision-making within a DAG.\nAn evaluation step receives multiple inputs and determines the next workflow step dynamically.\nEvaluation tasks are fully user-defined and can run arbitrary logic to decide next execution steps.\nEvaluation tasks can be used for conditional branching, error handling, or dynamic DAG construction.\nCan be used as an intercept point for manual approval or external system integration.\nEnables AI integration for dynamic decision-making based on task outcomes and range of available scheduling options.\nContext can be propagated onwards to ensure that any tasks scheduled as a result of the evaluation have the correct context.\n\n\n\n\n\nOAuth2 Support for enterprise authentication.\nBasic Auth for simple use cases.\nAPI Keys for programmatic access.\nRBAC (Role-Based Access Control) planned for future enterprise usage.\n\n\n\n\n\nWorkers dynamically scale based on queue depth on Kubernetes using Prometheus and HPA.\nOrchestrators self-distribute workloads using modulo hashing to allow for orchestrator scale-out on huge deployments.\nAffinity Rules allow specific tasks to be bound to specific worker pools (e.g., GPU workers, high-memory workers, compute intensive tasks).\nLabelling of tasks, queues, workers to support cost attribution in cloud environments.\n\n\n\n\n\nInstead of requiring local script uploads, Cyclonetix allows execution from Git repositories.\nSupports versioning of DAGs and tasks using Git branches/tags.\nUsers can specify Git repo, branch, and execution command for tasks.\n\n\n\n\n\nFor local development, Cyclonetix supports an in-memory execution mode.\nEnsures rapid iteration without requiring Redis or PostgreSQL.\nProduction environments can configure Redis/PostgreSQL for durability.\n\n\n\n\n\n\n\n\nFinalize task recovery logic and orchestrator state handling Prepare documentation (docs/ folder structure) Ensure Redis-based backend is working fully Develop and test PostgreSQL-based StateManager backend\n\n\n\n\nBuild the first version of the UI (Axum SSR + Tabler.js + Cytoscape.js)\nIntroduce event-driven execution triggers (Kafka, Webhooks, API calls)\nExpose REST API for external system integration\nRefine Kubernetes auto-scaling logic\nEnhance Git-based execution for versioned workflows\n\n\n\n\n\nCloud Deployment Automation (Terraform/Pulumi integration)\nJupyter Notebook Execution as DAGs (Convert annotated notebooks into production-ready workflows)\nWASM Execution Support (Ultra-lightweight task execution for simple workloads)\nLive Execution Tracking UI with WebSockets (Real-time updates on DAG execution state)\nMulti-tenancy support for organizations running shared workloads",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Cyclonetix: Comprehensive Design & Roadmap Document",
    "section": "",
    "text": "Cyclonetix is a lightweight, Rust-based workflow orchestrator designed to be fast, easy to use, and highly scalable. It is built for both cloud-native and on-premises deployments, supporting outcome-based scheduling, self-assembling DAGs, and manual DAG execution.\nUnlike traditional orchestrators, Cyclonetix aims to be: - Effortlessly simple to get started with - Exceptionally fast and lightweight - Flexible enough for both beginners and enterprise-scale workloads - Clever by design, reducing user cognitive load - Capable of advanced scheduling mechanisms (outcome-based scheduling + explicit DAG execution)",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#architecture",
    "href": "index.html#architecture",
    "title": "Cyclonetix: Comprehensive Design & Roadmap Document",
    "section": "",
    "text": "Cyclonetix consists of the following key components:\n\n\n\n\n\n\n\nComponent\nDescription\n\n\n\n\nOrchestrator\nBuilds execution graphs, evaluates task readiness, and schedules work.\n\n\nWorker\nPicks up tasks from queues and executes them.\n\n\nExecution Graph\nSelf-assembled DAG built from tasks, outcomes, and dependencies.\n\n\nState Manager (Redis, PostgreSQL, In-Memory Dev Mode)\nStores task states, execution metadata, and scheduled outcomes. Supports different backends for different environments.\n\n\nUI (Axum SSR + Tabler + Cytoscape.js)\nProvides real-time execution tracking and DAG visualization.\n\n\nAuthentication (OAuth, Basic Auth, API Keys)\nEnsures secure access to Cyclonetix resources.\n\n\n\n\n\n\n\nUsers schedule an “Outcome” (final goal/task)\nOrchestrator determines required tasks to complete the Outcome (self-assembling DAG)\nTasks are assigned to queues, picked up by workers, executed, and tracked in Redis or another backend\nCompleted tasks trigger evaluations for the next executable tasks via events\nExecution continues until the full DAG is completed\n\n\n\n\nCyclonetix supports two scheduling models: - Outcome-Based Scheduling (Self-assembling DAGs) - Users schedule an Outcome (e.g., deploy-model), and Cyclonetix dynamically determines the required execution steps. - Manual DAG Execution - Users define DAGs explicitly in YAML and execute them as structured workflows.\n\n\n\n\nContexts allow global state to be passed through execution graphs, ensuring variables and configurations are inherited properly.\nParameter Sets allow specific configurations to be associated with tasks, ensuring fine-grained control over execution and reuse of tasks with different “flavourings”. Parameters can be included in dependency declarations.\nContexts can be hierarchical, enabling seamless overrides for scoped execution. Base contexts loaded from repo and partially overridden by user-defined contexts values at scheduling time.\n**Support for common macros like ${DATE}, ${TIME}, ${RANDOM} for parameter and context values.\n\n\n\n\n\nEvaluation tasks allow dynamic decision-making within a DAG.\nAn evaluation step receives multiple inputs and determines the next workflow step dynamically.\nEvaluation tasks are fully user-defined and can run arbitrary logic to decide next execution steps.\nEvaluation tasks can be used for conditional branching, error handling, or dynamic DAG construction.\nCan be used as an intercept point for manual approval or external system integration.\nEnables AI integration for dynamic decision-making based on task outcomes and range of available scheduling options.\nContext can be propagated onwards to ensure that any tasks scheduled as a result of the evaluation have the correct context.\n\n\n\n\n\nOAuth2 Support for enterprise authentication.\nBasic Auth for simple use cases.\nAPI Keys for programmatic access.\nRBAC (Role-Based Access Control) planned for future enterprise usage.\n\n\n\n\n\nWorkers dynamically scale based on queue depth on Kubernetes using Prometheus and HPA.\nOrchestrators self-distribute workloads using modulo hashing to allow for orchestrator scale-out on huge deployments.\nAffinity Rules allow specific tasks to be bound to specific worker pools (e.g., GPU workers, high-memory workers, compute intensive tasks).\nLabelling of tasks, queues, workers to support cost attribution in cloud environments.\n\n\n\n\n\nInstead of requiring local script uploads, Cyclonetix allows execution from Git repositories.\nSupports versioning of DAGs and tasks using Git branches/tags.\nUsers can specify Git repo, branch, and execution command for tasks.\n\n\n\n\n\nFor local development, Cyclonetix supports an in-memory execution mode.\nEnsures rapid iteration without requiring Redis or PostgreSQL.\nProduction environments can configure Redis/PostgreSQL for durability.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#roadmap-next-steps",
    "href": "index.html#roadmap-next-steps",
    "title": "Cyclonetix: Comprehensive Design & Roadmap Document",
    "section": "",
    "text": "Finalize task recovery logic and orchestrator state handling Prepare documentation (docs/ folder structure) Ensure Redis-based backend is working fully Develop and test PostgreSQL-based StateManager backend\n\n\n\n\nBuild the first version of the UI (Axum SSR + Tabler.js + Cytoscape.js)\nIntroduce event-driven execution triggers (Kafka, Webhooks, API calls)\nExpose REST API for external system integration\nRefine Kubernetes auto-scaling logic\nEnhance Git-based execution for versioned workflows\n\n\n\n\n\nCloud Deployment Automation (Terraform/Pulumi integration)\nJupyter Notebook Execution as DAGs (Convert annotated notebooks into production-ready workflows)\nWASM Execution Support (Ultra-lightweight task execution for simple workloads)\nLive Execution Tracking UI with WebSockets (Real-time updates on DAG execution state)\nMulti-tenancy support for organizations running shared workloads",
    "crumbs": [
      "Introduction"
    ]
  }
]